{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Notebook\n",
    "This notebook will preprocess and leverage NLP models on the unstructured data to turn it into a usable feature space for modeling Tucker Carlson's body of work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports cell\n",
    "\n",
    "#Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the tucker document data either as a CSV or a pickle\n",
    "\n",
    "#Read out from CSV\n",
    "tucker_docs = pd.read_csv('data/tucker_docs.csv', encoding='UTF8', header = None).T\n",
    "\n",
    "#Read from pickle\n",
    "#tucker_docs = pd.read_pickle('data/tucker_pickle')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Test for fun\n",
    "tucker_docs.iloc[762,0][:416]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fox News host gives his take on pro-abortion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fox News host reflects on the left's respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fox News host gives his take on how Americans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fox News host gives his take on the Supreme C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fox News host gives his take on the real moti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0   Fox News host gives his take on pro-abortion ...\n",
       "1    Fox News host reflects on the left's respons...\n",
       "2   Fox News host gives his take on how Americans...\n",
       "3   Fox News host gives his take on the Supreme C...\n",
       "4   Fox News host gives his take on the real moti..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tucker_docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Bradley-Haderthauer Test\n",
    "Compare two topic distributions: IF BH-score is < 0.2, then a Twitterer can be confidently classified as a Tuckerbot. This person is a lower life form and unable to contribute, in good faith, to the deep state media platform of choice, Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make custom stops words to remove first 100 words? remove intro to episode \n",
    "#remove words in all caps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove words in all caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fox',\n",
       " 'news',\n",
       " 'host',\n",
       " 'give',\n",
       " 'take',\n",
       " 'pro',\n",
       " 'abortion',\n",
       " 'protester',\n",
       " 'targeting',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'justice',\n",
       " 'possible',\n",
       " 'overturn',\n",
       " 'roe',\n",
       " 'v',\n",
       " 'wade',\n",
       " 'tucker',\n",
       " 'carlson',\n",
       " 'tonight',\n",
       " 'pretty',\n",
       " 'hard',\n",
       " 'argue',\n",
       " 'people',\n",
       " 'passive',\n",
       " 'aggressive',\n",
       " 'may',\n",
       " 'tried',\n",
       " 'angry',\n",
       " 'scream',\n",
       " 'stop',\n",
       " 'violent',\n",
       " 'snarl',\n",
       " 'punch',\n",
       " 'face',\n",
       " 'passive',\n",
       " 'aggressive',\n",
       " 'people',\n",
       " 'intent',\n",
       " 'dominating',\n",
       " \"they're\",\n",
       " 'dishonest',\n",
       " 'admit',\n",
       " 'honorable',\n",
       " 'style',\n",
       " 'attack',\n",
       " 'effective',\n",
       " 'mostly',\n",
       " 'bewildering',\n",
       " 'democratic',\n",
       " 'party',\n",
       " 'practice',\n",
       " 'democrat',\n",
       " 'never',\n",
       " 'meet',\n",
       " 'open',\n",
       " 'field',\n",
       " 'battle',\n",
       " 'instead',\n",
       " 'sneak',\n",
       " 'behind',\n",
       " 'knock',\n",
       " 'unconscious',\n",
       " 'bag',\n",
       " 'sanctimony',\n",
       " 'party',\n",
       " 'weak',\n",
       " 'men',\n",
       " 'angry',\n",
       " 'woman',\n",
       " 'passive',\n",
       " 'aggression',\n",
       " 'mode',\n",
       " 'communication',\n",
       " 'ever',\n",
       " 'seen',\n",
       " 'one',\n",
       " 'jen',\n",
       " \"psaki's\",\n",
       " 'press',\n",
       " 'conference',\n",
       " 'know',\n",
       " 'exactly',\n",
       " \"we're\",\n",
       " 'talking',\n",
       " 'watched',\n",
       " 'one',\n",
       " 'yesterday',\n",
       " 'fact',\n",
       " 'last',\n",
       " 'peter',\n",
       " 'doocy',\n",
       " 'asked',\n",
       " 'psaki',\n",
       " 'administration',\n",
       " 'think',\n",
       " 'fact',\n",
       " 'liberal',\n",
       " 'group',\n",
       " 'posted',\n",
       " 'home',\n",
       " 'address',\n",
       " 'conservative',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'justice',\n",
       " 'internet',\n",
       " 'well',\n",
       " 'obvious',\n",
       " \"they're\",\n",
       " 'one',\n",
       " 'denies',\n",
       " \"they're\",\n",
       " \"they're\",\n",
       " 'order',\n",
       " 'frighten',\n",
       " 'justice',\n",
       " 'changing',\n",
       " 'vote',\n",
       " 'roe',\n",
       " 'v',\n",
       " 'wade',\n",
       " \"that's\",\n",
       " 'illegal',\n",
       " 'clearly',\n",
       " 'federal',\n",
       " 'crime',\n",
       " 'also',\n",
       " 'way',\n",
       " 'road',\n",
       " 'chaos',\n",
       " 'collapse',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'justice',\n",
       " 'samuel',\n",
       " 'alito',\n",
       " 'address',\n",
       " 'audience',\n",
       " 'emergency',\n",
       " 'docket',\n",
       " 'lecture',\n",
       " 'thursday',\n",
       " 'sept',\n",
       " 'mccartan',\n",
       " 'courtroom',\n",
       " 'university',\n",
       " 'notre',\n",
       " 'dame',\n",
       " 'law',\n",
       " 'school',\n",
       " 'south',\n",
       " 'bend',\n",
       " 'ind',\n",
       " 'michael',\n",
       " 'caterina',\n",
       " 'south',\n",
       " 'bend',\n",
       " 'tribune',\n",
       " 'via',\n",
       " \"can't\",\n",
       " 'allow',\n",
       " 'angry',\n",
       " 'mob',\n",
       " 'make',\n",
       " \"country's\",\n",
       " 'law',\n",
       " \"that's\",\n",
       " 'banned',\n",
       " 'lynching',\n",
       " 'jen',\n",
       " 'psaki',\n",
       " 'problem',\n",
       " 'people',\n",
       " 'understandably',\n",
       " 'upset',\n",
       " 'sam',\n",
       " \"alito's\",\n",
       " 'view',\n",
       " 'said',\n",
       " 'surprised',\n",
       " 'want',\n",
       " 'express',\n",
       " 'concern',\n",
       " 'person',\n",
       " 'screaming',\n",
       " 'sam',\n",
       " 'alito',\n",
       " 'family',\n",
       " 'official',\n",
       " 'government',\n",
       " 'position',\n",
       " 'people',\n",
       " 'protest',\n",
       " 'really',\n",
       " 'jen',\n",
       " 'psaki',\n",
       " 'rule',\n",
       " 'would',\n",
       " 'feel',\n",
       " 'angry',\n",
       " 'protester',\n",
       " 'showed',\n",
       " 'outside',\n",
       " 'say',\n",
       " 'michelle',\n",
       " \"obama's\",\n",
       " 'house',\n",
       " 'course',\n",
       " \"they'd\",\n",
       " 'thrown',\n",
       " 'thumbscrew',\n",
       " 'within',\n",
       " 'minute',\n",
       " 'charged',\n",
       " 'racism',\n",
       " 'would',\n",
       " 'applaud',\n",
       " 'languished',\n",
       " 'jail',\n",
       " 'conservative',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'justice',\n",
       " \"that's\",\n",
       " 'different',\n",
       " 'story',\n",
       " 'conservative',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'justice',\n",
       " 'deserve',\n",
       " \"that's\",\n",
       " 'jen',\n",
       " \"psaki's\",\n",
       " 'position',\n",
       " 'fact',\n",
       " 'since',\n",
       " \"we've\",\n",
       " 'speaking',\n",
       " 'topic',\n",
       " 'official',\n",
       " 'position',\n",
       " 'government',\n",
       " 'according',\n",
       " 'code',\n",
       " 'official',\n",
       " 'position',\n",
       " 'government',\n",
       " 'allowed',\n",
       " 'intimidate',\n",
       " 'judge',\n",
       " 'period',\n",
       " 'whoever',\n",
       " 'intent',\n",
       " 'interfering',\n",
       " 'obstructing',\n",
       " 'impeding',\n",
       " 'administration',\n",
       " 'justice',\n",
       " 'intent',\n",
       " 'influencing',\n",
       " 'judge',\n",
       " 'juror',\n",
       " 'witness',\n",
       " 'court',\n",
       " 'officer',\n",
       " 'discharge',\n",
       " 'duty',\n",
       " 'picket',\n",
       " 'parade',\n",
       " 'near',\n",
       " 'building',\n",
       " 'housing',\n",
       " 'court',\n",
       " 'united',\n",
       " 'state',\n",
       " 'near',\n",
       " 'building',\n",
       " 'residence',\n",
       " 'occupied',\n",
       " 'used',\n",
       " 'judge',\n",
       " 'juror',\n",
       " 'witness',\n",
       " 'court',\n",
       " 'officer',\n",
       " 'intent',\n",
       " 'us',\n",
       " 'sound',\n",
       " 'truck',\n",
       " 'similar',\n",
       " 'device',\n",
       " 'resort',\n",
       " 'demonstration',\n",
       " 'near',\n",
       " 'building',\n",
       " 'residence',\n",
       " 'shall',\n",
       " 'fined',\n",
       " 'imprisoned',\n",
       " 'clearly',\n",
       " 'crime',\n",
       " 'jen',\n",
       " 'psaki',\n",
       " 'either',\n",
       " 'know',\n",
       " 'far',\n",
       " 'likely',\n",
       " 'care',\n",
       " 'far',\n",
       " 'biden',\n",
       " 'administration',\n",
       " 'concerned',\n",
       " 'justice',\n",
       " 'alito',\n",
       " 'responsible',\n",
       " 'threat',\n",
       " 'family',\n",
       " 'want',\n",
       " 'targeted',\n",
       " 'mob',\n",
       " 'write',\n",
       " 'opinion',\n",
       " 'mob',\n",
       " 'like',\n",
       " 'dumbo',\n",
       " 'fault',\n",
       " \"we're\",\n",
       " 'hurting',\n",
       " \"that's\",\n",
       " 'always',\n",
       " 'position',\n",
       " 'passive',\n",
       " 'aggressive',\n",
       " 'people',\n",
       " 'position',\n",
       " 'passive',\n",
       " 'aggressive',\n",
       " 'party',\n",
       " 'recognized',\n",
       " 'immediately',\n",
       " 'watch',\n",
       " 'stuff',\n",
       " 'living',\n",
       " 'saw',\n",
       " 'made',\n",
       " 'u',\n",
       " 'think',\n",
       " 'ran',\n",
       " 'morning',\n",
       " 'day',\n",
       " 'assumed',\n",
       " 'based',\n",
       " 'quite',\n",
       " 'bit',\n",
       " 'evidence',\n",
       " 'main',\n",
       " 'threat',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'justice',\n",
       " 'right',\n",
       " 'justice',\n",
       " 'system',\n",
       " 'come',\n",
       " 'group',\n",
       " 'activist',\n",
       " 'liberal',\n",
       " 'enraged',\n",
       " 'idea',\n",
       " 'roe',\n",
       " 'v',\n",
       " 'wade',\n",
       " 'might',\n",
       " 'repealed',\n",
       " 'people',\n",
       " 'spray',\n",
       " 'painting',\n",
       " 'church',\n",
       " 'putting',\n",
       " 'sam',\n",
       " \"alito's\",\n",
       " 'home',\n",
       " 'address',\n",
       " 'internet',\n",
       " \"they're\",\n",
       " 'mob',\n",
       " \"they're\",\n",
       " 'angry',\n",
       " 'know',\n",
       " \"they're\",\n",
       " 'angry',\n",
       " 'whole',\n",
       " 'thing',\n",
       " 'made',\n",
       " 'sense',\n",
       " 'u',\n",
       " 'according',\n",
       " \"that's\",\n",
       " \"what's\",\n",
       " 'happening',\n",
       " 'fact',\n",
       " 'opposite',\n",
       " \"what's\",\n",
       " 'happening',\n",
       " 'real',\n",
       " 'threat',\n",
       " 'informed',\n",
       " 'u',\n",
       " 'morning',\n",
       " 'come',\n",
       " 'people',\n",
       " 'angry',\n",
       " 'sam',\n",
       " \"alito's\",\n",
       " 'opinion',\n",
       " 'people',\n",
       " 'happy',\n",
       " 'one',\n",
       " 'celebrating',\n",
       " 'sam',\n",
       " 'alito',\n",
       " 'wrote',\n",
       " 'one',\n",
       " 'real',\n",
       " 'danger',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'watch',\n",
       " 'morning',\n",
       " 'law',\n",
       " 'enforcement',\n",
       " 'official',\n",
       " 'preparing',\n",
       " 'potential',\n",
       " 'violence',\n",
       " 'capitol',\n",
       " 'nationwide',\n",
       " 'leak',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'draft',\n",
       " 'opinion',\n",
       " 'would',\n",
       " 'strike',\n",
       " 'roe',\n",
       " 'v',\n",
       " 'wade',\n",
       " 'year',\n",
       " 'capitol',\n",
       " 'police',\n",
       " 'warning',\n",
       " 'far',\n",
       " 'right',\n",
       " 'calling',\n",
       " 'violence',\n",
       " 'religious',\n",
       " 'group',\n",
       " 'planning',\n",
       " 'rally',\n",
       " 'abortion',\n",
       " 'right',\n",
       " 'whitney',\n",
       " 'wild',\n",
       " 'live',\n",
       " 'outside',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'listen',\n",
       " 'seeing',\n",
       " 'fence',\n",
       " 'go',\n",
       " 'sort',\n",
       " 'like',\n",
       " 'post',\n",
       " 'january',\n",
       " 'seeing',\n",
       " 'specific',\n",
       " 'intelligence',\n",
       " 'worrying',\n",
       " 'police',\n",
       " 'official',\n",
       " 'well',\n",
       " 'point',\n",
       " 'law',\n",
       " 'enforcement',\n",
       " 'source',\n",
       " 'several',\n",
       " 'tell',\n",
       " 'u',\n",
       " 'closely',\n",
       " 'monitoring',\n",
       " 'social',\n",
       " 'medium',\n",
       " 'chatter',\n",
       " 'suggests',\n",
       " \"there's\",\n",
       " 'potential',\n",
       " 'violence',\n",
       " 'abortion',\n",
       " 'clinic',\n",
       " 'provider',\n",
       " 'abortion',\n",
       " 'clinic',\n",
       " 'staff',\n",
       " 'member',\n",
       " 'judiciary',\n",
       " 'would',\n",
       " 'include',\n",
       " 'justice',\n",
       " 'well',\n",
       " 'member',\n",
       " 'federal',\n",
       " 'government',\n",
       " 'know',\n",
       " 'january',\n",
       " 'law',\n",
       " 'enforcement',\n",
       " 'know',\n",
       " 'across',\n",
       " 'country',\n",
       " 'social',\n",
       " 'medium',\n",
       " 'chatter',\n",
       " 'manifest',\n",
       " 'actual',\n",
       " 'violence',\n",
       " 'sometimes',\n",
       " 'people',\n",
       " 'really',\n",
       " 'say',\n",
       " \"they're\",\n",
       " 'going',\n",
       " 'got',\n",
       " 'law',\n",
       " 'enforcement',\n",
       " 'source',\n",
       " 'tell',\n",
       " 'real',\n",
       " 'threat',\n",
       " 'far',\n",
       " 'right',\n",
       " 'far',\n",
       " 'right',\n",
       " 'fence',\n",
       " 'going',\n",
       " 'outside',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'far',\n",
       " 'right',\n",
       " 'pose',\n",
       " 'threat',\n",
       " 'far',\n",
       " 'right',\n",
       " 'one',\n",
       " 'watch',\n",
       " \"they're\",\n",
       " 'one',\n",
       " 'whose',\n",
       " 'electronic',\n",
       " 'communication',\n",
       " 'got',\n",
       " 'monitor',\n",
       " 'closely',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'roe',\n",
       " 'v',\n",
       " 'wade',\n",
       " 'may',\n",
       " 'going',\n",
       " 'away',\n",
       " 'people',\n",
       " 'going',\n",
       " 'want',\n",
       " 'bomb',\n",
       " 'many',\n",
       " 'abortion',\n",
       " 'clinic',\n",
       " 'hurt',\n",
       " 'many',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'justice',\n",
       " 'possible',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'may',\n",
       " 'get',\n",
       " 'rid',\n",
       " 'law',\n",
       " 'hated',\n",
       " 'year',\n",
       " 'see',\n",
       " 'would',\n",
       " 'moved',\n",
       " 'violence',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'first',\n",
       " 'response',\n",
       " 'laugh',\n",
       " 'seems',\n",
       " 'absurd',\n",
       " 'real',\n",
       " 'dumb',\n",
       " 'think',\n",
       " 'remembered',\n",
       " 'president',\n",
       " 'united',\n",
       " 'state',\n",
       " 'attorney',\n",
       " 'general',\n",
       " 'telling',\n",
       " 'u',\n",
       " 'year',\n",
       " \"they've\",\n",
       " 'telling',\n",
       " 'u',\n",
       " 'matter',\n",
       " 'happens',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'look',\n",
       " 'like',\n",
       " 'people',\n",
       " 'vote',\n",
       " 'u',\n",
       " 'yeah',\n",
       " 'people',\n",
       " 'vote',\n",
       " 'u',\n",
       " 'dangerous',\n",
       " 'one',\n",
       " 'always',\n",
       " 'fault',\n",
       " 'watch',\n",
       " 'seen',\n",
       " 'dangerous',\n",
       " 'threat',\n",
       " 'democracy',\n",
       " 'invasion',\n",
       " 'capitol',\n",
       " 'greatest',\n",
       " 'terrorism',\n",
       " 'related',\n",
       " 'threat',\n",
       " 'face',\n",
       " 'homeland',\n",
       " 'threat',\n",
       " 'domestic',\n",
       " 'violent',\n",
       " 'extremism',\n",
       " 'according',\n",
       " 'intelligence',\n",
       " 'community',\n",
       " 'terrorism',\n",
       " 'white',\n",
       " 'supremacy',\n",
       " 'lethal',\n",
       " 'threat',\n",
       " 'homeland',\n",
       " 'today',\n",
       " 'al',\n",
       " 'qaeda',\n",
       " 'white',\n",
       " 'supremacist',\n",
       " 'al',\n",
       " 'qaeda',\n",
       " 'white',\n",
       " 'supremacy',\n",
       " 'reviewed',\n",
       " 'tape',\n",
       " 'started',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'like',\n",
       " 'mongol',\n",
       " 'visigoth',\n",
       " 'dreaded',\n",
       " 'white',\n",
       " 'supremacist',\n",
       " 'declared',\n",
       " 'war',\n",
       " 'civilization',\n",
       " 'trump',\n",
       " 'voter',\n",
       " 'evidence',\n",
       " 'around',\n",
       " 'u',\n",
       " \"we've\",\n",
       " 'ignored',\n",
       " 'level',\n",
       " 'want',\n",
       " 'know',\n",
       " 'retrospect',\n",
       " 'always',\n",
       " 'right',\n",
       " 'front',\n",
       " 'u',\n",
       " 'recall',\n",
       " 'trump',\n",
       " 'voter',\n",
       " 'looted',\n",
       " \"macy's\",\n",
       " 'new',\n",
       " 'york',\n",
       " 'city',\n",
       " 'help',\n",
       " \"that's\",\n",
       " 'torched',\n",
       " 'police',\n",
       " 'precinct',\n",
       " 'minneapolis',\n",
       " 'symbol',\n",
       " 'law',\n",
       " 'set',\n",
       " 'fire',\n",
       " 'burned',\n",
       " 'federal',\n",
       " 'building',\n",
       " 'portland',\n",
       " 'oregon',\n",
       " 'president',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'delivers',\n",
       " 'remark',\n",
       " 'debt',\n",
       " 'ceiling',\n",
       " 'event',\n",
       " 'state',\n",
       " 'dining',\n",
       " 'room',\n",
       " 'white',\n",
       " 'house',\n",
       " 'monday',\n",
       " 'oct',\n",
       " 'washington',\n",
       " 'photo',\n",
       " 'evan',\n",
       " 'vucci',\n",
       " 'case',\n",
       " 'forgotten',\n",
       " 'right',\n",
       " 'wing',\n",
       " 'attack',\n",
       " 'look',\n",
       " 'like',\n",
       " 'white',\n",
       " 'supremacist',\n",
       " \"here's\",\n",
       " 'see',\n",
       " \"they're\",\n",
       " 'putting',\n",
       " 'barrier',\n",
       " 'front',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'people',\n",
       " 'happy',\n",
       " 'sam',\n",
       " \"alito's\",\n",
       " 'opinion',\n",
       " 'might',\n",
       " 'start',\n",
       " 'burning',\n",
       " 'looting',\n",
       " 'course',\n",
       " 'would',\n",
       " 'consistent',\n",
       " 'year',\n",
       " 'long',\n",
       " 'reign',\n",
       " 'right',\n",
       " 'wing',\n",
       " 'terror',\n",
       " \"we've\",\n",
       " 'living',\n",
       " 'thirst',\n",
       " 'anarchy',\n",
       " 'chaos',\n",
       " 'never',\n",
       " 'sated',\n",
       " 'one',\n",
       " 'point',\n",
       " 'trump',\n",
       " 'voter',\n",
       " 'seceded',\n",
       " 'united',\n",
       " 'state',\n",
       " 'set',\n",
       " 'nation',\n",
       " 'lawlessness',\n",
       " 'drug',\n",
       " 'squalor',\n",
       " 'violence',\n",
       " 'within',\n",
       " 'city',\n",
       " 'limit',\n",
       " 'seattle',\n",
       " 'like',\n",
       " 'confederate',\n",
       " 'weed',\n",
       " 'spray',\n",
       " 'paint',\n",
       " 'right',\n",
       " 'middle',\n",
       " 'seattle',\n",
       " 'talk',\n",
       " 'brazen',\n",
       " \"that's\",\n",
       " 'could',\n",
       " 'happen',\n",
       " 'town',\n",
       " 'wonder',\n",
       " \"america's\",\n",
       " 'abortionist',\n",
       " 'community',\n",
       " 'cowering',\n",
       " 'fear',\n",
       " 'tonight',\n",
       " 'get',\n",
       " 'worse',\n",
       " 'people',\n",
       " 'little',\n",
       " 'respect',\n",
       " 'law',\n",
       " 'order',\n",
       " 'think',\n",
       " 'nothing',\n",
       " 'rushing',\n",
       " 'building',\n",
       " 'department',\n",
       " 'store',\n",
       " 'walgreens',\n",
       " 'liquor',\n",
       " 'store',\n",
       " 'foot',\n",
       " 'locker',\n",
       " 'taking',\n",
       " 'want',\n",
       " 'steal',\n",
       " 'armful',\n",
       " 'merchandise',\n",
       " 'shelf',\n",
       " 'walk',\n",
       " 'door',\n",
       " 'like',\n",
       " 'purely',\n",
       " 'amuse',\n",
       " 'push',\n",
       " 'stranger',\n",
       " 'front',\n",
       " 'train',\n",
       " 'open',\n",
       " 'fire',\n",
       " 'subway',\n",
       " 'car',\n",
       " 'drive',\n",
       " 'truck',\n",
       " 'christmas',\n",
       " 'parade',\n",
       " 'beat',\n",
       " 'elderly',\n",
       " 'asian',\n",
       " 'woman',\n",
       " 'street',\n",
       " \"can't\",\n",
       " 'control',\n",
       " 'people',\n",
       " \"they're\",\n",
       " 'beyond',\n",
       " 'reach',\n",
       " 'logic',\n",
       " 'primitive',\n",
       " 'superstitious',\n",
       " 'come',\n",
       " 'believe',\n",
       " 'defeat',\n",
       " 'nature',\n",
       " 'magic',\n",
       " 'amulet',\n",
       " 'like',\n",
       " 'cosmetic',\n",
       " \"women's\",\n",
       " 'clothing',\n",
       " 'think',\n",
       " \"they're\",\n",
       " 'shapeshifters',\n",
       " 'change',\n",
       " 'physical',\n",
       " 'form',\n",
       " 'become',\n",
       " 'something',\n",
       " 'different',\n",
       " 'seeing',\n",
       " 'one',\n",
       " 'screen',\n",
       " 'right',\n",
       " 'people',\n",
       " 'like',\n",
       " 'believe',\n",
       " 'history',\n",
       " 'science',\n",
       " \"they're\",\n",
       " 'barely',\n",
       " 'literate',\n",
       " 'communicate',\n",
       " 'instead',\n",
       " 'grunt',\n",
       " 'unintelligible',\n",
       " 'sound',\n",
       " \"here's\",\n",
       " 'leader',\n",
       " 'chief',\n",
       " 'tribe',\n",
       " 'speaking',\n",
       " 'language',\n",
       " 'understand',\n",
       " 'best',\n",
       " 'way',\n",
       " 'get',\n",
       " 'something',\n",
       " 'done',\n",
       " 'hold',\n",
       " 'near',\n",
       " 'dear',\n",
       " 'like',\n",
       " 'able',\n",
       " 'anyway',\n",
       " 'say',\n",
       " 'know',\n",
       " 'right',\n",
       " 'supremacist',\n",
       " 'person',\n",
       " 'understand',\n",
       " 'esoteric',\n",
       " 'language',\n",
       " 'primitive',\n",
       " 'adorn',\n",
       " 'body',\n",
       " 'fantastic',\n",
       " 'decoration',\n",
       " 'dress',\n",
       " 'costume',\n",
       " 'even',\n",
       " 'push',\n",
       " 'piece',\n",
       " 'metal',\n",
       " 'face',\n",
       " 'order',\n",
       " 'look',\n",
       " 'fierce',\n",
       " 'look',\n",
       " 'war',\n",
       " 'paint',\n",
       " 'hi',\n",
       " \"name's\",\n",
       " 'preschool',\n",
       " 'teacher',\n",
       " 'recently',\n",
       " 'started',\n",
       " 'wearing',\n",
       " 'pronoun',\n",
       " 'pin',\n",
       " 'kid',\n",
       " 'get',\n",
       " 'pick',\n",
       " 'new',\n",
       " 'pronoun',\n",
       " 'pin',\n",
       " 'every',\n",
       " 'day',\n",
       " 'pick',\n",
       " 'every',\n",
       " 'single',\n",
       " 'day',\n",
       " 'change',\n",
       " 'non',\n",
       " 'binary',\n",
       " 'preschool',\n",
       " 'teacher',\n",
       " 'kid',\n",
       " 'know',\n",
       " 'non',\n",
       " 'binary',\n",
       " 'know',\n",
       " 'girl',\n",
       " 'boy',\n",
       " 'use',\n",
       " 'pronoun',\n",
       " 'classroom',\n",
       " 'work',\n",
       " 'kid',\n",
       " 'get',\n",
       " \"that's\",\n",
       " 'okay',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tucker_doc = tucker_docs.iloc[0,0]\n",
    "#pattern to delete words in all caps\n",
    "#pattern = \"(([a-zA-Z]+(?:'[a-z]+)?))\"\n",
    "t_d = re.sub(r'\\b[A-Z]+\\b', '', tucker_doc)\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "tokenized_doc = nltk.regexp_tokenize(t_d, pattern)\n",
    "\n",
    "#lowercase all words\n",
    "tokenized_doc = [word.lower() for word in tokenized_doc]\n",
    "tokenized_doc\n",
    "\n",
    "#Freqdist\n",
    "td_freqdist = FreqDist(tokenized_doc)\n",
    "td_freqdist.most_common(75)\n",
    "\n",
    "#Stop words\n",
    "stopwords_list = stopwords.words('english')\n",
    "stop_tokenized_doc = [word for word in tokenized_doc if word not in stopwords_list]\n",
    "\n",
    "#Stopped freqdist \n",
    "stop_td_freqdist = FreqDist(stop_tokenized_doc)\n",
    "stop_td_freqdist.most_common(75)\n",
    "\n",
    "#lemmatize\n",
    "#to lem \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "#more lemmatizin\n",
    "#wnl.lemmatize(wn1.lemmatize(word) for word in stop_tokenized_doc)\n",
    "tokens = [wnl.lemmatize(word) for word in stop_tokenized_doc]\n",
    "tokens\n",
    "\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#def lemmatize_words(text):\n",
    "   # return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "#stop_tokenized_doc = stop_tokenized_doc.apply(lambda text: lemmatize_words(stop_tokenized_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess function to do all steps above at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "\n",
    "    #Step 0\n",
    "    #This is Praveen's code but it's not PEP-8 friendly so you should fix that for next cohort ty\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"@[a-z0-9_]+|#[a-z0-9_]+@[A-Z0-9_]+|#[A-Z0-9_]+|http\\S+\", \"\", text).strip().replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "   \n",
    "    #step 1: delete all caps words\n",
    "    t_d = re.sub(r'\\b[A-Z]+\\b', '', text)\n",
    "\n",
    "    #step 2: tokenize\n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    tokenized_doc = nltk.regexp_tokenize(t_d, pattern)\n",
    "\n",
    "    #step 3: stop words\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    stop_tokenized_doc = [word for word in tokenized_doc if word not in stopwords_list]\n",
    "\n",
    "    #step 4: lem\n",
    "    tokens = [wnl.lemmatize(word) for word in stop_tokenized_doc]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tucker_list = tucker_docs[0].tolist()\n",
    "new_list = []\n",
    "for each_doc in tucker_list:\n",
    "    new_list.append(preprocessing(each_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9z/tw9j8p_n7w3fdl6dpkycs1p00000gn/T/ipykernel_1117/1561738870.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnot_so_sparse_not_so_spicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "feature_names = new_list[0][0].get_feature_names()\n",
    "not_so_sparse_not_so_spicy = pd.DataFrame(new_list[0][1].toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortionist</th>\n",
       "      <th>absurd</th>\n",
       "      <th>according</th>\n",
       "      <th>across</th>\n",
       "      <th>activist</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>worse</th>\n",
       "      <th>would</th>\n",
       "      <th>write</th>\n",
       "      <th>wrote</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1169 rows Ã— 660 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  abortion  abortionist  absurd  according  across  activist  actual  \\\n",
       "0       0         0            0       0          0       0         0       0   \n",
       "782     0         0            0       0          0       0         0       0   \n",
       "781     0         0            0       0          0       0         0       0   \n",
       "780     0         0            0       0          0       0         0       0   \n",
       "779     0         0            0       0          0       0         0       0   \n",
       "..    ...       ...          ...     ...        ...     ...       ...     ...   \n",
       "386     0         0            0       0          0       0         0       0   \n",
       "392     0         0            0       0          0       0         0       0   \n",
       "384     0         0            0       0          0       0         0       0   \n",
       "101     0         0            0       0          0       0         0       0   \n",
       "137     0         0            0       0          0       0         0       0   \n",
       "\n",
       "     actually  address  ...  worse  would  write  wrote  ya  yeah  year  \\\n",
       "0           0        0  ...      0      0      0      0   0     0     0   \n",
       "782         0        0  ...      0      0      0      0   0     0     0   \n",
       "781         0        0  ...      0      0      0      0   0     0     0   \n",
       "780         0        0  ...      0      0      0      0   0     0     0   \n",
       "779         0        0  ...      0      0      0      0   0     0     0   \n",
       "..        ...      ...  ...    ...    ...    ...    ...  ..   ...   ...   \n",
       "386         0        0  ...      0      0      0      0   0     0     0   \n",
       "392         0        0  ...      0      0      0      0   0     0     0   \n",
       "384         0        1  ...      0      0      0      0   0     0     0   \n",
       "101         0        1  ...      0      0      0      0   0     0     0   \n",
       "137         0        1  ...      0      0      0      0   0     0     0   \n",
       "\n",
       "     yesterday  york  young  \n",
       "0            0     0      0  \n",
       "782          0     0      0  \n",
       "781          0     0      0  \n",
       "780          0     0      0  \n",
       "779          0     0      0  \n",
       "..         ...   ...    ...  \n",
       "386          0     0      0  \n",
       "392          0     0      0  \n",
       "384          0     0      0  \n",
       "101          0     0      0  \n",
       "137          0     0      0  \n",
       "\n",
       "[1169 rows x 660 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_so_sparse_not_so_spicy.sort_values(by = ['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vectorize.fit_transform(new_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1169x660 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1174 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('data/unique_tweets_list.csv').drop(columns = ['Unnamed: 0'])\n",
    "#tweet_df['tweet_history'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "len(ast.literal_eval(tweet_df.iloc[750,:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(s):\n",
    "    try:\n",
    "        l = ast.literal_eval(s)\n",
    "    except:\n",
    "        l = None\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['tweet_history'] = tweet_df['tweet_history'].apply(lambda x: string_to_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tweets(tweet_row):\n",
    "    tweet_list = []\n",
    "    for n in range(len(tweet_row)):\n",
    "        tweet_list.append(preprocessing(tweet_row[n]))\n",
    "\n",
    "    cleaned_tweets = []\n",
    "    for tweet in tweet_list:\n",
    "        if len(tweet) > 20:\n",
    "            cleaned_tweets.append(tweet)\n",
    "    return cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['cleaned_tweets'] = tweet_df['tweet_history'].apply(lambda x: prepare_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legislative genius nancy need go away take diane done useless corporate democrat',\n",
       " 'imagine female journos stay twitter musk charge twitter journalism lazy journalism anyway leave force orgs leave well msn departs twitter done simple',\n",
       " 'poised lose congress party ban book amp reproductive right amp record end s mc think colossally effed pull public begging fight paralyzed',\n",
       " \"good riddance let's watch replace withsomeone even worse\",\n",
       " \"hell's party standing firmly resolutely many u asking since turn performative b kabuki theater win fight would thunk\",\n",
       " 'ana kasparian young turk absolutely killing last day tired feckless corp might want tune party beholden corp donor interest way priority list',\n",
       " 'stop letting asshats play u performative fundraising nonsense find way vote people give damn u fight u',\n",
       " 'clear response elected dems scotus decision vote senate bill chance passing filibuster confront say get everyone record everyone know already',\n",
       " 'protected abortion right vigorously insider trading know draft scotus decision really mean fundraising vote asshole starting today let play u',\n",
       " \"case thought missed something important intrepid team's press conference fact run capitol stair fast enough upon questioned eliminating filibuster pretty much said\",\n",
       " \"poll progress court expansion campaign issue hour they're even politically incompetent think get idea national bloodstream step christian nationalism\",\n",
       " 'collins blamed gorsuch kavanaugh potentially misleading view abortion ya think',\n",
       " 'chief justice robert ordered investigation called egregious breach trust overturning stare decisis blah blah blah roe settled law commitment senate confirmation exactly',\n",
       " 'laugh medium meatheads think leak roe decision make court look political',\n",
       " \"world's richest man swoop buy public square never never public square\",\n",
       " 'war correspondent indeed courageous insult associate white house press corp timid ask tough question interested access career advancement truth one wish earned backslapping',\n",
       " 'sure great little speech maybe press self examination le backslapping orgs pushed iraq war largely approved year afghanistan gave trump billion dollar free campaign coverage',\n",
       " 'well make dc people doubt rest world known since december',\n",
       " 'putin get really desperate always hide merrick garland like press ever show asking question',\n",
       " 'wtf article contains weird stuff madison cawthorn may point republican orgy previously known',\n",
       " 'gonna ban book whole library play hope apply standard ban bible everyone get behind kind thing turn law unenforceable legal mess',\n",
       " \"netflix lost value growth slowed wonder much twitter's b evaporate half domestic user base cancel\",\n",
       " 'people saying google using cloud ai machine learning algorithm discover world merrick garland whereistheag',\n",
       " 'dc reaction mi state sen mallory mcmorrow going viral campaign receiving k day wow voter like defend constituent like rep pushover wimp fighting try copying',\n",
       " 'fact news dc terrify democrat throughout country',\n",
       " \"call old fashioned week insurrectionist revelation emerges including speaker house saying potus admitted starting said insurrection would think ag might want know news conference tell u he's\",\n",
       " \"one faith government branch would setting lifetime disappointment trust verify way we've given reason trust\",\n",
       " \"that's response appeal authority fallacy answer surgeon i'm remarkably good recognizing removing splinter thanks chuckle\",\n",
       " \"interesting jurisdiction e g ga worried public fbi comment ongoing investigation sure unless day election joe biden's son stop believing medium management demand justice\",\n",
       " 'oh naive crap sure single leak hyper political dc grand jury leak nope subpoena nope public knowing investigation would make trumpers likely lawyer amp delay start yelling persecution already',\n",
       " 'raskin said committee would prove coordinated attempt among trump top aide key supporter overturn election meaningless unless ag garland grows pair say quietly case sure',\n",
       " 'good leaf bad precedent hanging judge need get slapped cdc asks justice department appeal judge ruling struck mask mandate',\n",
       " 'example could happen worthy name',\n",
       " 'ruffle lot feather criticizing deserve good policy god awful political strategist one day going realize people including moderate respect vote party stand something fight',\n",
       " \"possibly least surprising development week personally problem dropping facebook i'll problem dropping twitter turn libertarian sh show\",\n",
       " \"anyone else stunned lack outrage abortion law r ramming doubt organized resistance happening degree making headline i'm baffled visibly organizing around\",\n",
       " 'mark meadow removed n c voter roll amid fraud investigation smart money say prove beyond shadow doubt guilty refuse prosecute like every investigation',\n",
       " \"every member every medium platform letting public know best bring trump's inflation control learned nothing r true repeated\",\n",
       " \"gt gop pollster say republican lawmaker laughing trump behind back think he's child lt say republican trump laughter momentary relief recognition cowardice\",\n",
       " \"manchin amp sinema coy reviving part bbb plan dems hope they're strung along hope hope many time need get kicked ball learn something supposed smart one\",\n",
       " 'inflation control biden run morning america theme worked really well reagan',\n",
       " 'kind dressing go well word salad',\n",
       " \"hey know who's never worried looking political partisan republican\",\n",
       " 'member worried criminal referral look political know look political spending year amp million uncovering evidence vast coup nothing make midterm political ad',\n",
       " \"look like d's blather making sure never happens many predicted huge load crap none plotter brought justice going happen without referral meaningless political theater\",\n",
       " 'anyone needed proof democrat weak pathetic party look fact thus far forwarded criminal complaint charge need put new team field primary season',\n",
       " 'understand men like dad go thrash teacher many people asking men seditious russia compromised fox news host',\n",
       " 'good come become another billionaire menace society',\n",
       " \"okay that's game let's start dismantling fox news today\",\n",
       " 'unreasonable require people reach certain level maturity making life altering decision sexuality identity added ok religious instruction stop brainwashing grooming child',\n",
       " 'consider even among top dumbest republican house member',\n",
       " \"never learn mistake can't\",\n",
       " \"well one sadder attempt last word i've seen awhile grant indeed legend mind briefly concerned got hurt patting back imagine muscle well stretched champ\",\n",
       " \"yeah enjoyable unilaterally pronounced mature wise worldly well yawn bottom line d's spent mo prepared run unmanifested policy ignoring else e g culture war hope sense enthusiasm\",\n",
       " 'transport bill result lay whatever merit fundamentally corp bonanza stood chance failure might well brag passing defense bill good luck running mostly unstarted project r take much credit',\n",
       " \"that's wrong everyone working neuron knew bbb dead detached transport bill everyone know outcome would worse progressive stood ground caved anyway party humiliated process\",\n",
       " 'nice day pangloss make sure allow slightest criticism puncture self assured bubble',\n",
       " \"compromising turn end way always humiliation meaningless symbolism placated corp d's every turn still got screwed end day separated transportation bill bbb\",\n",
       " \"btw made better argument electing that's problem anything remotely close effective national medium message presence\",\n",
       " \"voter care manchin sinema result especially whole campaign crafted around policy accomplishment materialize r's msg simple fear amp hate liberal take country back absence pushback working\",\n",
       " \"that's basically wash general r's globetrotter role appearance competition reality mostly r lite since decline union donor lost prob blame progressive pas go collect\",\n",
       " 'blaming someone else always productive strategy d held congress wh month power world shape narrative nothing r carpet bomb medium daily consistent message d spend minute maddow',\n",
       " 'never seen calm face kind disaster facing fall hair fire pro tip run bad opposition crap party',\n",
       " 'looking planning rally conspiracy theory surrounded event pfft month stench medium management face criticism',\n",
       " 'looking planning rally conspiracy theory surrounded event pfft took month talk trying manage press receiving public pressure',\n",
       " 'rt announced ramping investigation hunter biden huh shy ann',\n",
       " 'headline likely kevin expecting',\n",
       " 'time merrick garland job resign least punt appoint special prosecutor',\n",
       " 'wow everyone see merrick garland spring action latest j trump revelation kidding',\n",
       " 'never understood performative b going cut time biden told donor nothing fundamentally change mission accomplished touch critical historical moment',\n",
       " 'day since congress sent mark meadow criminal contempt referral cricket merrick garland prove latest long line gutless d stone need done',\n",
       " 'christian nationalism violent reclamation movement going move promise multi religious multi ethnic democracy force going confronted pay attention fooling around prepare',\n",
       " \"another trump fundraising scam remember month ago going sue tech company collected kind money towards end how's coming along thing succeed judge dummy send money\",\n",
       " \"gqp party can't stop talking freedom liberty incompetent lose dirt bag\",\n",
       " 'love god medium stop misusing term conspiracy theory time nothing conspiratorial theoretical fabricated lie need called',\n",
       " 'process bottom continue build hold everyone accountable committed criminal act respect j nice word day single subpoena grand jury etc trump elite',\n",
       " 'ok lucy get back u ball ever move single promised delivered outcome judicial history',\n",
       " \"good point inaction fact political least drop comment ongoing investigation garbage let u know what's happening d pressuring fact providing excuse medium he's running da\",\n",
       " \"love using people's money love poorly educated need plane befitting majesty money tied ruble\",\n",
       " 'ag need appoint special counsel dt offer best way reassure country one law justice nonpartisan blah blah blah guaranteed time waster garland need grow pair end story',\n",
       " 'remember even troop poised invade ukrainian writing american warning alarmist right invasion welcome american liberal right telling plan kidding',\n",
       " 'believe actively investigating trump inner circle',\n",
       " \"that's exactly right added advantage exactly law supposed work everyone\",\n",
       " 'agreed impossible underestimate gutless d bet history show without liz cheney j would written little report fund raised cowered prospect anything',\n",
       " 'r warn trump prosecution seen political boost trump within gop prevent biden pivoting center unifying country biz usual biz usual laughable gas lighting',\n",
       " 'chance show go law take prove one law protect elite show u longer invested constitutional system either',\n",
       " 'nothing ever going happen rich connected department',\n",
       " 'eastman warned granting access email could amount finding trump may committed crime sitting president defense losing attorney privilege crime involved admit crime involved',\n",
       " 'merrick job move time past time deadline merrick',\n",
       " 'day since jan th enough time decide whether live country law men enough enough',\n",
       " 'article email contains worth time result oriented position would never support attempted opposition essentially entirely made thanks bullshit siege',\n",
       " 'enough comment ongoing investigation horse crap merrick garland tell u intention get way time set deadline prepare massive springtime dc demonstration u',\n",
       " \"turn trump's wall useful degree trump university absolutely one full time trump kool aid drinker surprised\",\n",
       " 'absolute best outcome could hoped',\n",
       " 'screwed u twice merrick garland denied scotus spot might done well instead end ag position completely wrong man time please resign mr garland']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['cleaned_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tweet_vectorizer = TfidfVectorizer()\n",
    "tweet_df['vectorized'] = tweet_df['cleaned_tweets'].apply(lambda x: tweet_vectorizer.(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c1f5ce8eed932a4317a88fdfc83317a84584de98614c992901b7b196b5e3487"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
